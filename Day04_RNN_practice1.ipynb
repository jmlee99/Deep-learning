{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a96e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d379fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0       1       2       3       4       5       6\n",
      "0  361749  372412  388899  404408  423227  455207  487362\n",
      "1  239517  247444  259525  269903  284416  304543  326866\n",
      "2  243678  254076  266434  275898  297865  324841  355657\n",
      "3  163577  165169  171424  174614  182364  193948  212385\n",
      "4  169391  179605  188136  195544  205165  228842  240932\n",
      "5  103551  104856  107497  110236  116015  122848  133061\n",
      "(5, 6, 1)\n",
      "(5, 1)\n",
      "(1, 6, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('성_및_연령별_1인가구__시군구_20230619204703.csv', encoding = 'cp949', header = [0,1])\n",
    "data.columns = [x for x in np.arange(9)]\n",
    "data.drop([0, 1], axis = 1, inplace = True)\n",
    "data.columns = [x for x in np.arange(7)]\n",
    "print(data)\n",
    "\n",
    "X = np.expand_dims(data.iloc[:, :6], -1)\n",
    "y = np.expand_dims(data.iloc[:, -1], -1)\n",
    "X_train = X[1:]\n",
    "X_test = np.expand_dims(X[0],0)\n",
    "y_train = y[1:]\n",
    "y_test = np.expand_dims(y[0],0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf6375d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 70838738944.0000 - mae: 253780.0469\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 70838730752.0000 - mae: 253780.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 70838722560.0000 - mae: 253780.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 70838706176.0000 - mae: 253779.9531\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 70838697984.0000 - mae: 253779.9531\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 70838689792.0000 - mae: 253779.9219\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 70838681600.0000 - mae: 253779.9062\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 70838665216.0000 - mae: 253779.9062\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 70838648832.0000 - mae: 253779.8438\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 70838648832.0000 - mae: 253779.8438\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 237521338368.0000 - mae: 487361.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[237521338368.0, 487361.59375]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = keras.Sequential([\n",
    "    keras.layers.SimpleRNN(10, input_shape=(None, 1), return_sequences=True),\n",
    "    keras.layers.SimpleRNN(5)\n",
    "    ])\n",
    "m.compile(loss = 'mse', optimizer = 'adam', metrics='mae')\n",
    "m.fit(X_train, y_train, epochs = 10)\n",
    "m.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f79e54a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
      " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
      " ...\n",
      " list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459])\n",
      " list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23])\n",
      " list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])]\n"
     ]
    }
   ],
   "source": [
    "#### Sentiment Analysis\n",
    "(x_train, y_train),(x_test, y_test) = keras.datasets.imdb.load_data()\n",
    "print(x_train)\n",
    "\n",
    "\n",
    "r_dict = keras.datasets.imdb.get_word_index()\n",
    "reverse_dict = dict((i+3, w) for (w, i) in r_dict.items())\n",
    "reverse_dict[0] = '<pad>'\n",
    "reverse_dict[1] = '<sos>'\n",
    "reverse_dict[2] = '<unk>'\n",
    "#print(reverse_dict)\n",
    "\n",
    "def decode_review(rev_dict, encoded_review):\n",
    "    return '  '.join(rev_dict[i] for i in encoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aea639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<sos>  this  film  was  just  brilliant  casting  location  scenery  story  direction  everyone's  really  suited  the  part  they  played  and  you  could  just  imagine  being  there  robert  redford's  is  an  amazing  actor  and  now  the  same  being  director  norman's  father  came  from  the  same  scottish  island  as  myself  so  i  loved  the  fact  there  was  a  real  connection  with  this  film  the  witty  remarks  throughout  the  film  were  great  it  was  just  brilliant  so  much  that  i  bought  the  film  as  soon  as  it  was  released  for  retail  and  would  recommend  it  to  everyone  to  watch  and  the  fly  fishing  was  amazing  really  cried  at  the  end  it  was  so  sad  and  you  know  what  they  say  if  you  cry  at  a  film  it  must  have  been  good  and  this  definitely  was  also  congratulations  to  the  two  little  boy's  that  played  the  part's  of  norman  and  paul  they  were  just  brilliant  children  are  often  left  out  of  the  praising  list  i  think  because  the  stars  that  play  them  all  grown  up  are  such  a  big  profile  for  the  whole  film  but  these  children  are  amazing  and  should  be  praised  for  what  they  have  done  don't  you  think  the  whole  story  was  so  lovely  because  it  was  true  and  was  someone's  life  after  all  that  was  shared  with  us  all\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "decode_review(reverse_dict, x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75f81306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218 189 141 ... 184 150 153]\n",
      "(25000, 11)\n"
     ]
    }
   ],
   "source": [
    "review_len = np.array([len(review) for review in x_train])\n",
    "print(review_len)\n",
    "x_train_cut = []\n",
    "for review in x_train:\n",
    "    x_train_cut.append(review[:review_len.min()])\n",
    "x_train_cut = np.array(x_train_cut)\n",
    "print(x_train_cut.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a853dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_word_count = len(r_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3e0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 37s 45ms/step - loss: 0.6318 - accuracy: 0.6019\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 34s 43ms/step - loss: 0.4553 - accuracy: 0.7675\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.2765 - accuracy: 0.8724\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.1679 - accuracy: 0.9244\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 32s 41ms/step - loss: 0.1167 - accuracy: 0.9466\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 33s 42ms/step - loss: 0.0877 - accuracy: 0.9608\n",
      "Epoch 7/10\n",
      "592/782 [=====================>........] - ETA: 8s - loss: 0.0645 - accuracy: 0.9707"
     ]
    }
   ],
   "source": [
    "m = keras.Sequential([\n",
    "    keras.layers.Embedding(dict_word_count, 32, input_length=11),\n",
    "    keras.layers.SimpleRNN(32),\n",
    "    keras.layers.Dense(11, activation = 'relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "m.compile(optimizer='adam', loss = keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "m.fit(x_train_cut, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('busan_mintemp.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ea337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f'tf.__version__: {tf.__version__}')\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.list_physical_devices('GPU') 이 코드도 가능\n",
    "for gpu in gpus:\n",
    "    print(gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
