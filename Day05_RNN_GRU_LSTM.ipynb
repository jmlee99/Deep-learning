{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca64ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "979937e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1]\n",
      "  [2]\n",
      "  [3]]] (1, 3, 1)\n",
      "[<tf.Variable 'simple_rnn_11/simple_rnn_cell_11/kernel:0' shape=(1, 3) dtype=float32, numpy=array([[0.5, 0.5, 0.5]], dtype=float32)>, <tf.Variable 'simple_rnn_11/simple_rnn_cell_11/recurrent_kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
      "array([[1., 1., 1.],\n",
      "       [1., 1., 1.],\n",
      "       [1., 1., 1.]], dtype=float32)>, <tf.Variable 'simple_rnn_11/simple_rnn_cell_11/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_11 (SimpleRNN)   (None, 3)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = np.arange(1*3*1).reshape(1,3,1)\n",
    "data = data+1\n",
    "print(data, data.shape)\n",
    "\n",
    "# 한개의 layer에 한개의 Unit만 적용된 것이다. 데이터 아직 input X\n",
    "m = keras.Sequential([\n",
    "    keras.layers.SimpleRNN(3, input_shape=(None, 1), activation=None,\n",
    "                          kernel_initializer = keras.initializers.Constant(0.5),\n",
    "                          recurrent_initializer =  keras.initializers.Ones())\n",
    "])\n",
    "\n",
    "print(m.layers[0].weights)\n",
    "m.summary()\n",
    "#m.predict(data) # RNN 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973783a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.arange(1*3*1).reshape(1,3,1)\n",
    "data = data+1\n",
    "print(data, data.shape)\n",
    "\n",
    "# 한개의 layer에 한개의 Unit만 적용된 것이다. 데이터 아직 input X\n",
    "m = keras.Sequential([\n",
    "    keras.layers.LSTM(1, input_shape=(None, 1), activation=None,\n",
    "                          kernel_initializer = keras.initializers.Constant(0.5),\n",
    "                          recurrent_initializer =  keras.initializers.Ones())\n",
    "])\n",
    "\n",
    "print(m.layers[0].weights)\n",
    "m.summary()\n",
    "#m.predict(data) # RNN 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ce25667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1]\n",
      "  [2]\n",
      "  [3]]] (1, 3, 1)\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "[<tf.Variable 'gru/gru_cell/kernel:0' shape=(1, 3) dtype=float32, numpy=array([[0.5, 0.5, 0.5]], dtype=float32)>, <tf.Variable 'gru/gru_cell/recurrent_kernel:0' shape=(1, 3) dtype=float32, numpy=array([[1., 1., 1.]], dtype=float32)>, <tf.Variable 'gru/gru_cell/bias:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32)>]\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = np.arange(1*3*1).reshape(1,3,1)\n",
    "data = data+1\n",
    "print(data, data.shape)\n",
    "\n",
    "# 한개의 layer에 한개의 Unit만 적용된 것이다. 데이터 아직 input X\n",
    "m = keras.Sequential([\n",
    "    keras.layers.GRU(1, input_shape=(None, 1), activation=None,\n",
    "                          kernel_initializer = keras.initializers.Constant(0.5),\n",
    "                          recurrent_initializer =  keras.initializers.Ones())\n",
    "])\n",
    "\n",
    "print(m.layers[0].weights)\n",
    "m.summary()\n",
    "#m.predict(data) # RNN 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "362e9db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 20:28:47.880872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[10.,  0.]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention layer\n",
    "#Sequential 모델이 아니라 Functional 모델이다.\n",
    "\n",
    "query = tf.keras.layers.Input(shape=(None,3,))\n",
    "value = tf.keras.layers.Input(shape=(4,2,)) \n",
    "key = tf.keras.layers.Input(shape=(4,3,))\n",
    "\n",
    "x = tf.keras.layers.Attention()([query, value, key])\n",
    "model = tf.keras.models.Model(inputs=[query, value, key], outputs=x)\n",
    "\n",
    "temp_k = tf.constant([[[10,0,0],\n",
    "                       [0,10,0],\n",
    "                       [0,0,10],\n",
    "                       [0,0,10]]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[[   1,0],\n",
    "                       [  10,0],\n",
    "                       [ 100,5],\n",
    "                       [1000,6]]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "temp_q = tf.constant([[[0, 10, 0]]], dtype=tf.float32)  # (1, 3)\n",
    "\n",
    "model.predict([temp_q,temp_v,temp_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f7abf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계\n",
      "(1, 1, 3)\n",
      "(1, 4, 3)\n",
      "(1, 1, 4) tf.Tensor([[[  0. 100.   0.   0.]]], shape=(1, 1, 4), dtype=float32)\n",
      "\n",
      "2단계\n",
      "(1, 1, 4) tf.Tensor([[[0. 1. 0. 0.]]], shape=(1, 1, 4), dtype=float32)\n",
      "\n",
      "3단계\n",
      "(1, 1, 2) tf.Tensor([[[10.  0.]]], shape=(1, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Attention layer의 연산과정이다. \n",
    "\n",
    "# Key하고 query값을 곱해서 \n",
    "print('1단계')\n",
    "print(temp_q.shape)\n",
    "print(temp_k.shape)\n",
    "\n",
    "scores = tf.matmul(temp_q, temp_k, transpose_b = True)\n",
    "#matrics multi\n",
    "print(scores.shape, scores)\n",
    "\n",
    "print('')\n",
    "\n",
    "# 그 곱한 값을 softmax값을 통과시키고\n",
    "print('2단계')\n",
    "dist = tf.nn.softmax(scores)\n",
    "print(dist.shape, dist)\n",
    "\n",
    "print('')\n",
    "\n",
    "# 그 softmax통과한 값을 value와 더하는 것이 attention 연산이 되는 과정이다.\n",
    "print('3단계')\n",
    "out = tf.matmul(dist, temp_v)\n",
    "print(out.shape, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b361942",
   "metadata": {},
   "source": [
    "![nn](1_wT3X_UAZ6MAI_hdqejUVMQ.webp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
